{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtiene la ruta absoluta a la raíz del proyecto (ajusta según tu estructura)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.predict import cargar_modelo, predecir, evaluar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos el modelo y las funciones que necesitamos del notebook 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model/random_forest.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rfc \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./model/random_forest.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kurtc\\Documentos\\GitHub\\producto-datos-lab\\.venv\\lib\\site-packages\\joblib\\numpy_pickle.py:735\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[0;32m    733\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj, ensure_native_byte_order\u001b[38;5;241m=\u001b[39mensure_native_byte_order)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 735\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m             fobj,\n\u001b[0;32m    738\u001b[0m             validated_mmap_mode,\n\u001b[0;32m    739\u001b[0m         ):\n\u001b[0;32m    740\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    741\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    742\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    743\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model/random_forest.joblib'"
     ]
    }
   ],
   "source": [
    "rfc = joblib.load(\"./model/random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feat = [\n",
    "\"pickup_weekday\",\n",
    "\"pickup_hour\",\n",
    "'work_hours',\n",
    "\"pickup_minute\",\n",
    "\"passenger_count\",\n",
    "'trip_distance',\n",
    "'trip_time',\n",
    "'trip_speed'\n",
    "]\n",
    "categorical_feat = [\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"RatecodeID\",\n",
    "]\n",
    "EPS = 1e-7\n",
    "features = numeric_feat + categorical_feat\n",
    "target_col = \"high_tip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, target_col):\n",
    "\n",
    "   # Basic cleaning\n",
    "    df = df[df['fare_amount'] > 0].reset_index(drop=True)  # avoid divide-by-zero\n",
    "    # add target\n",
    "    df['tip_fraction'] = df['tip_amount'] / df['fare_amount']\n",
    "    df[target_col] = df['tip_fraction'] > 0.2\n",
    "\n",
    "    # add features\n",
    "    df['pickup_weekday'] = df['tpep_pickup_datetime'].dt.weekday\n",
    "    df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "    df['pickup_minute'] = df['tpep_pickup_datetime'].dt.minute\n",
    "    df['work_hours'] = (df['pickup_weekday'] >= 0) & (df['pickup_weekday'] <= 4) & (df['pickup_hour'] >= 8) & (df['pickup_hour'] <= 18)\n",
    "    df['trip_time'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.seconds\n",
    "    df['trip_speed'] = df['trip_distance'] / (df['trip_time'] + EPS)\n",
    "\n",
    "    # drop unused columns\n",
    "    df = df[['tpep_dropoff_datetime'] + features + [target_col]]\n",
    "    df[features + [target_col]] = df[features + [target_col]].astype(\"float32\").fillna(-1.0)\n",
    "\n",
    "    # convert target to int32 for efficiency (it's just 0s and 1s)\n",
    "    df[target_col] = df[target_col].astype(\"int32\")\n",
    "\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación Enero 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enero-2020 F1: 0.7074542897327707\n"
     ]
    }
   ],
   "source": [
    "taxi_march= pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-01.parquet')\n",
    "taxi_test = preprocess(taxi_march, target_col=target_col).head(1000)\n",
    "taxi_test.head()\n",
    "\n",
    "preds_test = rfc.predict_proba(taxi_test[features])\n",
    "preds_test_labels = [p[1] for p in preds_test.round()]\n",
    "print(f'enero-2020 F1: {f1_score(taxi_test[target_col], preds_test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test.to_csv('./app/data/yellow_tripdata_2020-01_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación Febrero 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "febrero-2020 F1: 0.7456492637215528\n"
     ]
    }
   ],
   "source": [
    "taxi_march= pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-02.parquet')\n",
    "taxi_test = preprocess(taxi_march, target_col=target_col).head(1000)\n",
    "taxi_test.head()\n",
    "\n",
    "preds_test = rfc.predict_proba(taxi_test[features])\n",
    "preds_test_labels = [p[1] for p in preds_test.round()]\n",
    "print(f'febrero-2020 F1: {f1_score(taxi_test[target_col], preds_test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test.to_csv('./app/data/yellow_tripdata_2020-02_test.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación Marzo 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marzo-2020 F1: 0.7408880053015242\n"
     ]
    }
   ],
   "source": [
    "taxi_march= pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-03.parquet')\n",
    "taxi_test = preprocess(taxi_march, target_col=target_col).head(1000)\n",
    "taxi_test.head()\n",
    "\n",
    "preds_test = rfc.predict_proba(taxi_test[features])\n",
    "preds_test_labels = [p[1] for p in preds_test.round()]\n",
    "print(f'marzo-2020 F1: {f1_score(taxi_test[target_col], preds_test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test.to_csv('./app/data/yellow_tripdata_2020-03_test.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación Abril 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abril-2020 F1: 0.5471698113207547\n"
     ]
    }
   ],
   "source": [
    "taxi_may= pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-04.parquet')\n",
    "taxi_test = preprocess(taxi_may, target_col=target_col).head(1000)\n",
    "taxi_test.head()\n",
    "\n",
    "preds_test = rfc.predict_proba(taxi_test[features])\n",
    "preds_test_labels = [p[1] for p in preds_test.round()]\n",
    "print(f'abril-2020 F1: {f1_score(taxi_test[target_col], preds_test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test.to_csv('./app/data/yellow_tripdata_2020-04_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación Mayo 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mayo-2020 F1: 0.5536723163841808\n"
     ]
    }
   ],
   "source": [
    "taxi_may= pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-05.parquet')\n",
    "taxi_test = preprocess(taxi_may, target_col=target_col).head(1000)\n",
    "taxi_test.head()\n",
    "\n",
    "preds_test = rfc.predict_proba(taxi_test[features])\n",
    "preds_test_labels = [p[1] for p in preds_test.round()]\n",
    "print(f'mayo-2020 F1: {f1_score(taxi_test[target_col], preds_test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test.to_csv('./app/data/yellow_tripdata_2020-05_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
